\section{Evaluation}
\label{eval}

%Evaluation section...
%
%Length: 3-4 pages (graphs take a lot of space!)
%
%Tell reader what to expect.
%
%Eval is "proof" that your design is good.
%MATCH eval goals with design goals.
%
%Eval section is easier to write, but longest one to produce
%results for.  Whereas design section has complex structure, eval
%is more 'flat'.
%
%Structure:
%
%1.  list eval goals, should match design goals
%
%2.  briefly list how you plan to prove those goals.
%
%3.  describe your testbed: h/w + s/w platform to run tests on.
%Give enough detail so it can be reproduced by ANYONE.
%
%4.  describe your benchmarks in detail:
%
%(4a) Micro benchmarks: test specific feature (e.g., read or
%write performance).  Usually u-bench are designed to highlight
%worst/best case behavior of your system.  Be to list both best
%and worst.
%
%(4b) Macro benchmarks (general purpose benchmarks): test whole
%system (e.g., run a Web server exerciser, or TPC for database).
%
%Some tests should compare YOUR system to past systems, or a
%"before and after" comparison.
%
%For every possible variable in your system, design a set of
%independent tests (re: compression study's dimensions).  Justify
%need to vary each variable (the more variables, the more
%experiments you have to run).
%
%5.  Describe your benchmarking methodology
%
%Statistical stability: how many times you run each test? do you
%compute standard deviations, half-width intervals (for student-t
%distribution), RMS, or other metric of stability?  Say how many
%times you ran each test, and what were the stability metrics.
%
%Ex."we ran every test at least 10 times, and computed the
%standard deviation as a percentage of the mean.  In all cases,
%the percentage was less than 5\%, unless otherwise noted."
%
%6.  List every benchmark result, for each test
%
%(a) a graph or table or other figure, plus caption.
%(b) followed by an explanation of the figure: say what one sees
%    in the figure, then explain WHY it is so.
%
%7.  Optional: if eval section longer than usual, end it with a
%one-paragraph summary of eval results.

\begin{table*}[th]
\small
\centering
\begin{tabular}{ c|c|c|c|c|c|c|c|c| }
\hline
\multicolumn{1}{|c|}{\textbf{Algorithm}} &
\multicolumn{2}{c}{\textbf{Aaswad}}&
  \multicolumn{2}{|c|}{\textbf{Arvind}} &
  \multicolumn{2}{|c|}{\textbf{Srikant}} &
  \multicolumn{2}{|c|}{\textbf{Bharat}} \\
  \cline{2-9}
  \multicolumn{1}{|c|}{} &
  Correct & In-correct & Correct & In-correct & Correct & In-correct & Correct & In-correct \\  \hline
    \hline
  \multicolumn{1}{|c|}{\textbf{K-means}}
& 50.0 & 50.0 & 67.41 & 32.58 & 55.68 & 44.31 & 66.29 & 33.70 \\ \hline
  \multicolumn{1}{|c|}{\textbf{Eigen-vector}}
& 86.66 & 13.33 & 90.0 & 10.0 & 86.66 & 13.33 & 83.33 & 16.66 \\ \hline
  \multicolumn{1}{|c|}{\textbf{Betweenness}}
& 73.33 & 26.66 & 70.0 & 30.0 & 66.66 & 33.33 & 76.66 & 23.33\\  \hline
  \multicolumn{1}{|c|}{\textbf{Closeness}}
& 76.66 & 23.33 & 86.66 & 13.33 & 76.66 & 23.33 & 73.33 & 26.66 \\ \hline
\end{tabular}

\caption{\capfont Accuracy (in \%) of prediction vs validated data from users}
\label{tab:Accuracy of Algorithms}
\end{table*}



\begin{figure*}[ht]
    \centering
    \includegraphics[width=1\textwidth]{figures/social-result_arvind.eps}
    \caption{Comparison of accuracy of algorithms, based on validated result data from Arvind.}
    \label{fig:social-result-arvind}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=1\textwidth]{figures/social-result_arvind_kmeans.eps}
    \caption{Comparison of accuracy of K-means on varying k, based on validated data from Arvind.}
    \label{fig:social-result-arvind-kmeans}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=1\textwidth]{figures/social-result_eigen.eps}
    \caption{Rank comparison for top 20 nodes ranked on eigenvector centrality with other centrality scores.}
    \label{fig:social-result-eigen}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=1\textwidth]{figures/social-result_closeness.eps}
    \caption{Rank comparison for top 20 nodes ranked on closeness centrality with other centrality scores.}
    \label{fig:social-result-closeness}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=1\textwidth]{figures/social-result_betweenness.eps}
    \caption{Rank comparison for top 20 nodes ranked on betweenness centrality with other centrality scores.}
    \label{fig:social-result-betweenness}
\end{figure*}

\paragraph{Data Collection}
For our experiments, we have collected Facebook ego network data for
the authors using facebook app "Give me my data"~\cite{givememydata}.
We also called for volunteers to give their data and verify the
results as they know the ground truth data.  For our experiment we
have assigned ids to each user in the data for privacy reasons. 

\paragraph{Results}
We picked assigned each nodes a rank based on the centrality score.
The nodes with higher importance score were ranked accordingly, 1
being the highest rank and $n$ being the lowest rank.  The ego in the
network always gets rank 1.  We then picked top 20 ranked nodes
according to each centrality score, and then compared how much rank
increment or decrement each nodes got in other measures of centrality
scores.

Figure~\ref{fig:social-result-eigen} shows the rank gain or lose for
top 20 nodes for eigenvector centrality scores when compared to other
centrality measures.  Here we can see that node 222, has the same rank
for all the three measures.  So, it shows that a node if it is really
important, remains important irrespective of centrality indicator.  We
can also see that there is not much gain or lose in rank when compared
to closeness centrality.  Node 109 gains a better rank when measured
on different centrality indicators.  But for all other nodes there is
significant drop in rank, when compared to betweenness centrality.

Figure~\ref{fig:social-result-closeness} shows the rank gain or lose for
top 20 nodes for closeness centrality scores when compared to other
centrality measures.  Here we can see that there is significant
overlap in top 20 nodes for closeness centrality and eigenvector
centrality.  Almost 15 nodes out of 20 are common for both the scales.
But when compared to betweenness centrality there is not much overlap.
But still the maximum drop to rank is not more than 45, that is less
than 10\% of the total nodes, 508.  This tells
that nodes that are important according to eigenvector centrality or
closeness centrality measures are really important nodes.  But when we
see the top 20 important nodes for betweenness centrality, see
figure~\ref{fig:social-result-betweenness}, nodes that rank high on
this score, are not among the high ranked nodes on the other
centrality indicators.  Betweenness centrality finds completely
different important nodes.  Some of these nodes are relatively less
important nodes in context of whole network, but these nodes work as a
bridge between two communities in the graph.  That is why these nodes
score high on betweenness centrality but low on other centrality
measures.

\input{table-results.tex}

We also had run k-means clustering algorithm on the ego network for
different k values.  For k-means clustering we have used shortest path
distance between two nodes after excluding the ego from the graph as a
distance metric.  After clustering the graph, we report centroid of
each group as important nodes.  Table~\ref{tab:k-means-results} shows
the important nodes that were reported for k=5 and their rank
according to different centrality measures.  For had varied the number
of clusters for $k=3,5,7,10,12,15,17,20$ and compared the reported
nodes with the ground truth data.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% For Emacs:
% Local variables:
% fill-column: 70
% End:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% For Vim:
% vim:textwidth=70
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LocalWords:
